{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-uirVvNW-yY"
   },
   "source": [
    "HHU Deep Representation Learning, Prof. Dr. Markus Kollmann\n",
    "\n",
    "Lecturers and Tutoring is done by Nikolas Adaloglou and Felix Michels.\n",
    "\n",
    "# Assignment 05 - Image Clustering\n",
    "---\n",
    "\n",
    "Submit the solved notebook (not a zip) with your full name plus assingment number for the filename as an indicator, e.g `max_mustermann_a1.ipynb` for assignment 1. If we feel like you have genuinely tried to solve the exercise, you will receive 1 point for this assignment, regardless of the quality of your solution.\n",
    "\n",
    "## <center> DUE FRIDAY 30.05.2025 2:30 pm </center>\n",
    "\n",
    "Drop-off link: [https://uni-duesseldorf.sciebo.de/s/lfg71DbYxyyT8e6](https://uni-duesseldorf.sciebo.de/s/lfg71DbYxyyT8e6)\n",
    "\n",
    "---\n",
    "# Introduction \n",
    "\n",
    "Image clustering in deep learning can be mathematically described as a process of partitioning a set of images, X, into K clusters, where K is a user-defined parameter representing the number of desired clusters.\n",
    "\n",
    "Let V(X) be the visual feature representation of the images in X, obtained using a deep learning algorithm such as a convolutional neural network (CNN). Each image in X is transformed into a feature vector in V(X), where the dimensions correspond to the learned features of the CNN.\n",
    "\n",
    "Image clustering is a task in deep learning where an algorithm is used to group similar images together based on their visual characteristics. Ideally, images with similar ground truth labels will belong in the same cluster.\n",
    "\n",
    "The goal of image clustering is to automatically categorize large sets of images into smaller subsets based on their similarities, which can help in organizing and managing large image datasets.\n",
    "\n",
    "To accomplish this task, deep learning algorithms use complex mathematical models to analyze and identify patterns within the images, and then group the images that share these patterns into clusters. This process can be useful in a variety of applications, such as image recognition, image search, and content-based image retrieval.\n",
    "\n",
    "\n",
    "[SimCLR Paper](https://arxiv.org/abs/2002.05709)\n",
    "\n",
    "[MoCo Paper](https://arxiv.org/abs/1911.05722)\n",
    "\n",
    "[SCAN Paper](https://arxiv.org/abs/2005.12320v2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/HHU-MMBS/RepresentationLearning_PUBLIC_2024/main/exercises/week05/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw5K7r5SQDca"
   },
   "source": [
    "\n",
    "### Imports, basic utils, augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SIad0uuHBlv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# Local imports\n",
    "from utils import *\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Load the pretrained MoCO model ResNet50 pretrained on ImageNet\n",
    "\n",
    "[Weights are available in this link](https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar)\n",
    "\n",
    "You can download the weight by running the terminal command:\n",
    "\n",
    "`$ wget link_to_model_weights`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moco_model(pretrained_path = \"./moco_v2_800ep_pretrain.pth.tar\"):\n",
    "    ### START CODE HERE ### (≈ 12 lines of code)\n",
    "    ### END CODE HERE ###\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "encoder = load_moco_model() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results\n",
    "\n",
    "There should be no missing keys, while loading the model. There may be some unexpected keys based on your implementation.\n",
    "\n",
    "```python\n",
    "Loaded model with message: _IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.0.weight', 'fc.0.bias', 'fc.2.weight', 'fc.2.bias'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4v-Qg5Xpk2Bv"
   },
   "source": [
    "## Task 2: Compute the k-means clustering accuracy using the learned representations\n",
    "\n",
    "\n",
    "Compute the accuracy both for the train and test split using k-means.\n",
    "\n",
    "- You can pre-compute the image feature representations\n",
    "- Use the labelled data of STL10 (train split).\n",
    "- Hint: you may use the function 'compute_clustering_metrics' defined in `utils.py``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeP4ZuZpsyOp"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (>10 lines of code)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results\n",
    "\n",
    "`Train acc: 55.86, Val acc: 55.86`\n",
    "\n",
    "Results may vary due to random initialization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: T-SNE visualization of features\n",
    "\n",
    "As in the previous exercise, check the results of linear probing on the supervised training split and the T-SNE visualization.\n",
    "\n",
    "Code for the T-SNE visualization exists in `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### ( 3 line of code)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected result\n",
    "![](https://raw.githubusercontent.com/HHU-MMBS/RepresentationLearning_PUBLIC_2024/main/exercises/week05/figs/tsne_plot_embeddings_solution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Compute the k=50 nearset neiboughrs on the feature space of the pretrained ResNet50\n",
    "\n",
    "- Use the cosine similarity\n",
    "- Visualize the top 5 NN for a couple of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided\n",
    "class_names = torchvision.datasets.STL10(root='../data').classes\n",
    "def vizualize_pairs(indices, true_labels, train_ds):\n",
    "    # Visualize the reference image and its 7 nearest neighbors\n",
    "    ref_ids = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    nn_viz = 6 \n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    plt.figure(figsize = (22,22))\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    for c, ref in enumerate(ref_ids):\n",
    "        knns = indices[ref, :nn_viz]\n",
    "        imgs_to_viz = [train_ds[ref][0]]\n",
    "        true_labels = [train_ds[ref][1]]\n",
    "        for i in knns:\n",
    "            imgs_to_viz.append(train_ds[i][0])\n",
    "            true_labels.append(train_ds[i][1])\n",
    "        # show the images\n",
    "        for j in range(nn_viz):\n",
    "            label = int(true_labels[j])\n",
    "            plt.subplot(len(ref_ids), nn_viz, (c*nn_viz)+(j+1))\n",
    "            imshow(imgs_to_viz[j])\n",
    "            plt.title(f\"{class_names[label]}, Label {label}\", fontsize = 10)\n",
    "            ax = plt.gca()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "    # plt.savefig(f'./figs/knn_viz', bbox_inches = \"tight\", dpi = 500) \n",
    "\n",
    "### START CODE HERE ### ( 7-8 line of code)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected result\n",
    "\n",
    "![](https://raw.githubusercontent.com/HHU-MMBS/RepresentationLearning_PUBLIC_2024/main/exercises/week05/figs/knn_viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Write a new dataset class to load image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PairSTL10(torch.utils.data.Dataset):\n",
    "    def __init__(self, indices_path=\"./knn_indices.pth\", embeds_path=\"./train_feats.pth\", l2_normalize=True):\n",
    "        ### START CODE HERE ###\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ### START CODE HERE ###\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "def test_get_pair():\n",
    "    dataset = PairSTL10()\n",
    "    emb1, emb2 = dataset[16]\n",
    "    print(emb1.shape, emb2.shape)\n",
    "    assert emb1.shape==emb2.shape \n",
    "\n",
    "test_get_pair()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(PairSTL10(), batch_size=128, shuffle=True, num_workers=4)\n",
    "data_batch = next(iter(train_loader))\n",
    "print(data_batch[0].shape, data_batch[1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "torch.Size([2048]) torch.Size([2048])\n",
    "torch.Size([128, 2048]) torch.Size([128, 2048])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Implement the SCAN loss. Train the clustering head and compute the validation accuracy.\n",
    "Paper: https://arxiv.org/abs/2005.12320 (semantic clustering loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCAN(torch.nn.Module):\n",
    "    def __init__(self, alpha=1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, proj_1, proj_2):\n",
    "        ### START CODE HERE ### (≈ 5 lines of code)       \n",
    "        ### END CODE HERE ###\n",
    "        return sim_loss + self.alpha * entropy_loss\n",
    "\n",
    "def test_scan():\n",
    "    torch.manual_seed(99)\n",
    "    scan = SCAN(alpha=1)\n",
    "    proj_1 = torch.randn(100, 128)\n",
    "    proj_2 = torch.randn(100, 128)\n",
    "    loss = scan(proj_1, proj_2)\n",
    "    print(loss)\n",
    "    assert loss.shape==torch.Size([])\n",
    "test_scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results\n",
    "\n",
    "For alpha=1, output = `tensor(0.0275)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Implement the PMI loss. \n",
    "Paper: https://arxiv.org/abs/2303.17896 (Section 3, Equation 8)\n",
    "- Typically methods have multiple clustering heads. We use just one here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMI(torch.nn.Module):\n",
    "    def __init__(self, gamma=1, momentum=0.99, temp=0.1):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.temp = temp\n",
    "        self.center  = None\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def forward(self, proj_1, proj_2):\n",
    "        ### START CODE HERE ###\n",
    "        ### END CODE HERE ###\n",
    "        return pmi_loss\n",
    "\n",
    "\n",
    "    def pmi(self, p1, p2, pk):\n",
    "        ### START CODE HERE ###\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update_ema(self, output):\n",
    "        \"\"\"\n",
    "        Update exponential moving average.\n",
    "        \"\"\"\n",
    "        batch_center = output.detach().mean(dim=0)\n",
    "        if self.center is None:\n",
    "            # Initialize center uniformly\n",
    "            self.center = torch.ones_like(batch_center) / batch_center.size(0)\n",
    "        ### START CODE HERE ### (1 line of code)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "\n",
    "def test_pmi():\n",
    "    torch.manual_seed(99)\n",
    "    criterion = PMI(gamma=1)\n",
    "    proj_1 = torch.rand(100, 128)\n",
    "    proj_2 = torch.rand(100, 128)\n",
    "    loss = criterion(proj_1, proj_2)\n",
    "    print(loss)\n",
    "    assert loss.shape==torch.Size([])\n",
    " \n",
    "test_pmi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results \n",
    "\n",
    "`tensor(0.0738)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Modify pretraining code\n",
    "\n",
    "- The previous training code will not work out of the box since now we load image pairs that are nearest neiboughrs in feature space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, alpha, student):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.teacher = copy.deepcopy(student)\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "    \n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        ### START CODE HERE ###\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    def update_teacher(self, student):\n",
    "        for ema_params, student_params in zip(self.teacher.parameters(), student.parameters()):\n",
    "            old_weight, student_weight = ema_params.data, student_params.data\n",
    "            ema_params.data = self.update_average(old_weight, student_weight)\n",
    "\n",
    "\n",
    "def pretrain_one_epoch(model, optimizer, train_loader, criterion, device, model_ema=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model_ema (bool, optional): Whether we use  an exponential moving \n",
    "        average for the second image/view. If false both images/views share the same\n",
    "        feature extractor. Defaults to False.\n",
    "    Returns:\n",
    "        the mean loss of the current epoch\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (≈ 12 lines of code)\n",
    "    ### END CODE HERE ###\n",
    "    return loss_curr_epoch\n",
    "\n",
    "# This will be given to the students\n",
    "def pretrain(model, optimizer, num_epochs, train_loader, criterion, device, prefix=\"scan\", model_ema=False):\n",
    "    dict_log = {\"train_loss\":[]}\n",
    "    best_loss = 1e8\n",
    "    model = model.to(device)\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for epoch in pbar:\n",
    "        loss_curr_epoch = pretrain_one_epoch(model, optimizer, train_loader, criterion, device, model_ema=model_ema)\n",
    "        msg = (f'Ep {epoch}/{num_epochs}: || Loss: Train {loss_curr_epoch:.3f}')\n",
    "        pbar.set_description(msg)\n",
    "        dict_log[\"train_loss\"].append(loss_curr_epoch)\n",
    "        if loss_curr_epoch < best_loss:\n",
    "            best_loss = loss_curr_epoch\n",
    "            save_model(model, f'{prefix}_best_model_min_val_loss.pth', epoch, optimizer, best_loss)   \n",
    "    return dict_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Train with SCAN and PMI using the KNN pairs\n",
    "\n",
    "Train the clustering head (a small MLP) and compute the validation accuracy for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PairSTL10(indices_path=\"./knn_indices.pth\", embeds_path=\"./train_feats.pth\", l2_normalize=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "criterion = SCAN(alpha=10)\n",
    "n_clusters = 10\n",
    "num_epochs = 150\n",
    "\n",
    "def get_mlp(n_clusters=10):\n",
    "    ### START CODE HERE\n",
    "    return torch.nn.Sequential(\n",
    "                torch.nn.Linear(2048, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, n_clusters))\n",
    "    ### END CODE HERE\n",
    "\n",
    "# SCAN\n",
    "scan_head = get_mlp(n_clusters=n_clusters)\n",
    "optimizer = torch.optim.Adam(scan_head.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "dict_log_scan = pretrain(scan_head, optimizer, num_epochs, train_loader, criterion, device, prefix=\"scan\")\n",
    "\n",
    "# PMI\n",
    "criterion = PMI(gamma=0.65, momentum=0.9, temp=0.1)\n",
    "pmi_head = get_mlp(n_clusters=n_clusters)\n",
    "optimizer = torch.optim.Adam(pmi_head.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "dict_log_pmi = pretrain(pmi_head, optimizer, num_epochs, train_loader, criterion, device, prefix=\"pmi\", model_ema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Get cluster assignments and evaluate cluster accuracy\n",
    "\n",
    "- The code you need to fill loads the feature and computes the logits (unnormalized output of the trained clustering head)\n",
    "- For details on how to preprocess the data, you need to mimic the training data pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_clustering(model):\n",
    "    model.eval()\n",
    "    val_feats, val_labels = torch.load(\"val_feats.pth\"), torch.load(\"val_labels.pth\")\n",
    "    train_feats, train_labels = torch.load(\"train_feats.pth\"), torch.load(\"train_labels.pth\")\n",
    "\n",
    "    ### START CODE HERE\n",
    "    train_feats = F.normalize(train_feats, dim=-1, p=2)\n",
    "    val_feats = F.normalize(val_feats, dim=-1, p=2)\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_feats, train_labels)\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_feats, val_labels)\n",
    "\n",
    "    train_feat_dl = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "    val_feat_dl = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    train_logits, _ = get_features(model, train_feat_dl, device)\n",
    "    val_logits, _ = get_features(model, val_feat_dl, device)\n",
    "    ### END CODE HERE\n",
    "\n",
    "\n",
    "    train_preds = train_logits.argmax(dim=-1).cpu().numpy()\n",
    "    val_preds =val_logits.argmax(dim=-1).cpu().numpy()\n",
    "    print(\"Unique preds\", np.unique(train_preds), np.unique(val_preds))\n",
    "    #assert len(np.unique(train_preds)) == n_clusters , \"Collapse! Number of predicted assignments is not equal to number of clusters\"\n",
    "    \n",
    "    metrics_train = compute_clustering_metrics(train_labels.cpu().numpy(), train_preds, min_samples_per_class=10)\n",
    "    metrics_val = compute_clustering_metrics(val_labels.cpu().numpy(), val_preds,min_samples_per_class=10)\n",
    "    return metrics_train[0], metrics_val[0]\n",
    "\n",
    "n_clusters = 10\n",
    "model = get_mlp(n_clusters=n_clusters)\n",
    "model_scan = load_model(model, \"./scan_best_model_min_val_loss.pth\")\n",
    "\n",
    "model = get_mlp(n_clusters=n_clusters)\n",
    "model_pmi = load_model(model, \"./pmi_best_model_min_val_loss.pth\")\n",
    "train_acc, val_acc = evaluate_clustering(model_scan)\n",
    "print(f\"SCAN: Train acc: {train_acc:.3f}, Val acc: {val_acc:.3f}\")\n",
    "train_acc, val_acc = evaluate_clustering(model_pmi)\n",
    "print(f\"PMI: Train acc: {train_acc:.3f}, Val acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results:\n",
    "Current best scores!\n",
    "```\n",
    "Model ./scan_best_model_min_val_loss.pth is loaded from epoch 148 , loss -22.383880043029784\n",
    "Model ./pmi_best_model_min_val_loss.pth is loaded from epoch 129 , loss -2.0719790697097777\n",
    "Unique preds [0 1 2 3 4 5 6 7 8 9] [0 1 2 3 4 5 6 7 8 9]\n",
    "SCAN: Train acc: 74.380, Val acc: 74.450\n",
    "Unique preds [0 1 2 3 4 5 6 7 8 9] [0 1 2 3 4 5 6 7 8 9]\n",
    "PMI: Train acc: 77.280, Val acc: 78.238\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "That's the end of this exercise. If you reached this point, congratulations!\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[Exercise 4] - SimCLR Resnet18 Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc5fcf396fe0abd4fa852aee332a0572494dcaf5776820055c87d9b84157f362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
